/**
 * INTELINK Document Extraction Service
 * 
 * Pipeline: Document â†’ Text Extraction â†’ LLM Analysis â†’ Structured JSON
 * Supports: PDF, DOCX, DOC, TXT, "Free Mode" (raw text input)
 */

import fs from 'fs';
import path from 'path';

// Dynamic imports for parsers (Node.js only)
// eslint-disable-next-line @typescript-eslint/no-explicit-any
let pdfParse: any = null;
// eslint-disable-next-line @typescript-eslint/no-explicit-any
let mammoth: any = null;

async function getPdfParse() {
    if (!pdfParse) {
        const module = await import('pdf-parse');
        pdfParse = module.default || module;
    }
    return pdfParse;
}

async function getMammoth() {
    if (!mammoth) {
        mammoth = await import('mammoth');
    }
    return mammoth;
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// TYPES
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

export type DocumentType = 
    | 'reds'           // REDS - Registro de Eventos de Defesa Social
    | 'relatorio'      // RelatÃ³rio de ServiÃ§o
    | 'depoimento'     // Depoimento/Testemunho
    | 'apreensao'      // Auto de ApreensÃ£o
    | 'laudo'          // Laudo Pericial
    | 'mandado'        // Mandado
    | 'comunicacao'    // ComunicaÃ§Ã£o Interna (CS)
    | 'livre';         // Modo Livre (texto sem estrutura)

export type EntityType = 'PERSON' | 'VEHICLE' | 'LOCATION' | 'ORGANIZATION' | 'FIREARM' | 'PHONE' | 'DOCUMENT';

export interface ExtractedEntity {
    type: EntityType;
    name: string;
    role?: string; // suspeito, vÃ­tima, testemunha, etc.
    confidence: number; // 0-1
    metadata: Record<string, string | number | boolean | null>;
}

export interface ExtractedRelationship {
    source: string;
    target: string;
    type: string; // DRIVING, OWNER, ACCOMPLICE, VICTIM_OF, SEEN_AT, etc.
    description: string;
    confidence: number;
}

export interface TimelineEvent {
    datetime?: string;
    description: string;
    entities_involved: string[];
}

export interface ExtractionResult {
    success: boolean;
    document_type: DocumentType;
    model_used: string;
    processing_time_ms: number;
    raw_text?: string;
    summary: string;
    entities: ExtractedEntity[];
    relationships: ExtractedRelationship[];
    timeline: TimelineEvent[];
    insights: string[];
    warnings: string[];
    raw_llm_response?: string;
    error?: string;
}

export interface ModelConfig {
    name: string;
    provider: 'openrouter';
    model_id: string;
    max_tokens: number;
    cost_per_1k_input?: number;
    cost_per_1k_output?: number;
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// AVAILABLE MODELS (via OpenRouter)
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

export const AVAILABLE_MODELS: ModelConfig[] = [
    {
        name: 'Gemini 2.0 Flash',
        provider: 'openrouter',
        model_id: 'google/gemini-2.0-flash-001',
        max_tokens: 8192,
        cost_per_1k_input: 0,
        cost_per_1k_output: 0
    },
    {
        name: 'GPT-4o',
        provider: 'openrouter',
        model_id: 'openai/gpt-4o',
        max_tokens: 4096,
        cost_per_1k_input: 0.005,
        cost_per_1k_output: 0.015
    },
    {
        name: 'GPT-4o Mini',
        provider: 'openrouter',
        model_id: 'openai/gpt-4o-mini',
        max_tokens: 4096,
        cost_per_1k_input: 0.00015,
        cost_per_1k_output: 0.0006
    },
    {
        name: 'Claude 3.5 Sonnet',
        provider: 'openrouter',
        model_id: 'anthropic/claude-3.5-sonnet',
        max_tokens: 4096,
        cost_per_1k_input: 0.003,
        cost_per_1k_output: 0.015
    },
    {
        name: 'Llama 3.3 70B',
        provider: 'openrouter',
        model_id: 'meta-llama/llama-3.3-70b-instruct',
        max_tokens: 4096,
        cost_per_1k_input: 0.00035,
        cost_per_1k_output: 0.0004
    },
    {
        name: 'DeepSeek V3',
        provider: 'openrouter',
        model_id: 'deepseek/deepseek-chat',
        max_tokens: 4096,
        cost_per_1k_input: 0.00014,
        cost_per_1k_output: 0.00028
    }
];

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// META-PROMPTS
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

// PROMPT V5 - Schema baseado no i2 Analyst's Notebook (padrÃ£o mundial)
// Entidades = ALVOS de operaÃ§Ã£o (nÃ£o metadados, nÃ£o evidÃªncias)
const SYSTEM_PROMPT_EXTRACTION = `VocÃª Ã© um Analista de InteligÃªncia Criminal usando o padrÃ£o i2 Analyst's Notebook.

REGRA FUNDAMENTAL: ENTIDADES sÃ£o ALVOS DE INVESTIGAÃ‡ÃƒO, nÃ£o metadados.

## ENTIDADES (extraia apenas estas categorias):

1. **PERSON** - Pessoas ENVOLVIDAS no crime (nÃ£o policiais, nÃ£o advogados)
   - Autores/Suspeitos
   - VÃ­timas
   - Testemunhas relevantes
   - Metadata: cpf, rg, vulgo, idade, mae, pai, endereco, telefone, ocupacao

2. **VEHICLE** - VeÃ­culos relacionados ao crime
   - Metadata: placa, modelo, cor, marca, ano, chassi, renavam

3. **LOCATION** - APENAS locais do crime ou relevantes
   - Local do fato, esconderijo, ponto de encontro
   - NÃƒO inclua delegacias ou unidades policiais
   - Metadata: endereco, bairro, cidade, uf, coordenadas

4. **PHONE** - NÃºmeros de telefone (linhas SIM)
   - Formato: (DDD) XXXXX-XXXX
   - NÃƒO inclua aparelhos fÃ­sicos (sÃ£o evidÃªncias)

5. **ORGANIZATION** - APENAS facÃ§Ãµes criminosas ou quadrilhas
   - PCC, CV, milÃ­cias, gangues (4+ pessoas organizadas)
   - NÃƒO inclua empresas normais, delegacias ou unidades PM

6. **FIREARM** - Armas de fogo
   - Metadata: tipo, calibre, marca, numero_serie

## EVIDÃŠNCIAS (separado das entidades):

- Drogas apreendidas
- Aparelhos celulares (fÃ­sicos, com IMEI)
- Dinheiro
- Documentos
- Outros materiais

## NÃƒO SÃƒO ENTIDADES (guardar como metadata):

- Policiais (vÃ£o em metadata.policiais)
- Advogados (vÃ£o em metadata.advogados)
- Pai/MÃ£e de envolvidos (vÃ£o dentro da entidade PERSON)
- Delegacias/Unidades PM (vÃ£o em metadata.unidade_responsavel)
- Empresas normais como Correios, aplicativos (menÃ§Ã£o no texto)

## FORMATO JSON:

{
  "document_type": "reds|cs|relatorio|depoimento",
  "numero_ocorrencia": "",
  "data_fato": "AAAA-MM-DD HH:MM",
  "natureza": "",
  "summary": "Resumo em 2-3 frases",
  "historico_completo": "TEXTO INTEGRAL do histÃ³rico narrativo",
  
  "entities": [
    {"type": "PERSON", "name": "NOME", "role": "autor|vÃ­tima|testemunha", "confidence": 1.0, "metadata": {"cpf":"", "rg":"", "vulgo":"", "idade":0, "mae":"", "pai":"", "endereco":"", "telefone":"", "ocupacao":""}}
  ],
  
  "evidences": [
    {"type": "DRUG|DEVICE|MONEY|DOCUMENT", "description": "", "quantity": "", "details": {"imei":"", "marca":"", "modelo":""}}
  ],
  
  "relationships": [
    {"source": "NOME1", "target": "NOME2", "type": "ACCOMPLICE|OWNER|FAMILY|LIVES_AT|WORKS_AT|MEMBER_OF", "description": ""}
  ],
  
  "timeline": [
    {"datetime": "", "description": "", "entities_involved": []}
  ],
  
  "metadata": {
    "policiais": [{"nome": "", "cargo": "", "matricula": ""}],
    "advogados": [{"nome": ""}],
    "unidade_responsavel": ""
  },
  
  "insights": [],
  "warnings": []
}

IMPORTANTE: Retorne APENAS JSON vÃ¡lido, sem markdown.`;

// PROMPT V7 - Para RELATÃ“RIOS/CS (documentos subjetivos de investigadores)
// Inclui achados investigativos (provas subjetivas)
const SYSTEM_PROMPT_RELATORIO = `VocÃª Ã© um Analista de InteligÃªncia Criminal SÃŠNIOR processando um RELATÃ“RIO DE INVESTIGADOR (CS).

## MISSÃƒO CRÃTICA
Extrair TODAS as informaÃ§Ãµes relevantes, identificando:
- CONEXÃ•ES entre entidades
- PADRÃ•ES de comportamento criminoso
- HIERARQUIAS dentro de grupos
- LINHAS DE INVESTIGAÃ‡ÃƒO prioritÃ¡rias
- ACHADOS INVESTIGATIVOS (provas subjetivas)

## REGRAS DE CONFIANÃ‡A (CONFIDENCE)
- 0.9-1.0: Fato documentado, dado explÃ­cito
- 0.8: AnÃ¡lise tÃ©cnica (ERB, extraÃ§Ã£o celular)
- 0.7: IndicaÃ§Ã£o forte do investigador
- 0.6: HipÃ³tese/suspeita com alguma base
- 0.5: MenÃ§Ã£o indireta

## EXTRAIA:

1. **PESSOAS** - TODOS os mencionados com vulgos, telefones, funÃ§Ãµes criminais
2. **VEÃCULOS** - Placa, modelo, adulteraÃ§Ãµes
3. **LOCAIS** - Biqueiras, mocÃ³s, pontos de venda
4. **TELEFONES** - Com IMEI quando disponÃ­vel
5. **RELACIONAMENTOS** - Hierarquias (LEADER_OF), parcerias (ACCOMPLICE), famÃ­lia (FAMILY)
6. **ACHADOS INVESTIGATIVOS** - ImpressÃµes do investigador que NÃƒO sÃ£o provas periciais
7. **LINHAS DE INVESTIGAÃ‡ÃƒO** - HipÃ³teses com prÃ³ximos passos concretos

## FORMATO JSON:

{
  "document_type": "relatorio",
  "numero_cs": "CS XX/2025",
  "autor_relatorio": "Nome do Investigador",
  "data_relatorio": "YYYY-MM-DD",
  "unidade": "",
  "summary": "Resumo analÃ­tico em 3-5 frases",
  "historico_completo": "TEXTO INTEGRAL",
  
  "entities": [
    {
      "type": "PERSON|VEHICLE|LOCATION|PHONE",
      "name": "NOME EM MAIÃšSCULAS",
      "role": "suspeito|vitima|testemunha|pessoa_de_interesse",
      "confidence": 0.8,
      "metadata": {
        "vulgo": "",
        "funcao_criminal": "lÃ­der|executor|mandante|receptador",
        "telefone": "(XX) XXXXX-XXXX",
        "crimes_relacionados": []
      }
    }
  ],
  
  "relationships": [
    {
      "source": "NOME1",
      "target": "NOME2",
      "type": "LEADER_OF|ACCOMPLICE|FAMILY|RIVAL|SUPPLIER|CUSTOMER",
      "description": "DescriÃ§Ã£o do vÃ­nculo",
      "confidence": 0.8
    }
  ],
  
  "achados_investigativos": [
    {
      "tipo": "interview_impression|surveillance_obs|technical_analysis|connection_hypothesis|modus_operandi|source_intel",
      "titulo": "TÃ­tulo curto descritivo",
      "descricao": "DescriÃ§Ã£o completa do achado",
      "entidades_envolvidas": ["NOME1", "NOME2"],
      "confidence": 0.7,
      "acao_sugerida": "PrÃ³ximo passo concreto"
    }
  ],
  
  "linhas_investigacao": [
    {
      "hipotese": "DescriÃ§Ã£o clara da hipÃ³tese",
      "entidades_envolvidas": ["NOME1", "NOME2"],
      "prioridade": "alta|mÃ©dia|baixa",
      "proximo_passo": "AÃ§Ã£o concreta: Ouvir X, cruzar dados Y"
    }
  ],
  
  "timeline": [
    {
      "datetime": "YYYY-MM-DD",
      "description": "O que aconteceu",
      "entities_involved": [],
      "tipo": "crime|vigilÃ¢ncia|anÃ¡lise_tÃ©cnica|informaÃ§Ã£o"
    }
  ],
  
  "insights": ["PadrÃµes identificados"],
  "warnings": ["ATENÃ‡ÃƒO: InformaÃ§Ãµes subjetivas"],
  "recomendacoes_cruzamento": ["Cruzar com balÃ­stica", "Verificar outros REDS"]
}

REGRAS CRÃTICAS:
- Retorne APENAS JSON vÃ¡lido, SEM markdown
- EXTRAIA TODOS os dados, mesmo parciais
- Use MAIÃšSCULAS para nomes prÃ³prios
- IDENTIFIQUE hierarquias criminais (quem lidera quem)
- ACHADOS INVESTIGATIVOS sÃ£o observaÃ§Ãµes do investigador, NÃƒO provas periciais`;

// Mapa de prompts por tipo de documento
const PROMPTS_BY_TYPE: Record<DocumentType, string> = {
    'reds': SYSTEM_PROMPT_EXTRACTION,
    'relatorio': SYSTEM_PROMPT_RELATORIO,
    'comunicacao': SYSTEM_PROMPT_RELATORIO, // CS usa mesmo prompt de relatÃ³rio
    'depoimento': SYSTEM_PROMPT_EXTRACTION, // Depoimentos sÃ£o mais factuais
    'apreensao': SYSTEM_PROMPT_EXTRACTION,
    'laudo': SYSTEM_PROMPT_EXTRACTION,
    'mandado': SYSTEM_PROMPT_EXTRACTION,
    'livre': SYSTEM_PROMPT_EXTRACTION
};

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// TEXT EXTRACTION FROM FILES
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

export async function extractTextFromFile(filePath: string): Promise<{ text: string; type: string }> {
    const ext = path.extname(filePath).toLowerCase();
    const buffer = fs.readFileSync(filePath);
    
    switch (ext) {
        case '.pdf':
            const pdf = await getPdfParse();
            const pdfData = await pdf(buffer);
            return { text: pdfData.text, type: 'pdf' };
            
        case '.docx':
            const mammothLib = await getMammoth();
            const docxResult = await mammothLib.extractRawText({ buffer });
            return { text: docxResult.value, type: 'docx' };
            
        case '.doc':
            // .doc files are trickier - mammoth doesn't support them directly
            // For now, we'll try mammoth and fall back to error
            try {
                const mammothLibDoc = await getMammoth();
                const docResult = await mammothLibDoc.extractRawText({ buffer });
                return { text: docResult.value, type: 'doc' };
            } catch {
                throw new Error('Arquivos .doc antigos nÃ£o sÃ£o suportados diretamente. Converta para .docx ou PDF.');
            }
            
        case '.txt':
            return { text: buffer.toString('utf-8'), type: 'txt' };
            
        default:
            throw new Error(`Formato nÃ£o suportado: ${ext}`);
    }
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// LLM EXTRACTION
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

export async function extractWithLLM(
    text: string,
    model: ModelConfig,
    documentHint?: DocumentType
): Promise<ExtractionResult> {
    const start = Date.now();
    
    const apiKey = process.env.OPENROUTER_API_KEY;
    if (!apiKey) {
        return {
            success: false,
            document_type: documentHint || 'livre',
            model_used: model.name,
            processing_time_ms: Date.now() - start,
            summary: '',
            entities: [],
            relationships: [],
            timeline: [],
            insights: [],
            warnings: [],
            error: 'OPENROUTER_API_KEY nÃ£o configurada'
        };
    }

    const userPrompt = documentHint 
        ? `Tipo de documento: ${documentHint.toUpperCase()}\n\nConteÃºdo:\n${text}`
        : `Analise o documento abaixo e identifique seu tipo:\n\n${text}`;

    // Selecionar prompt baseado no tipo de documento
    const systemPrompt = documentHint 
        ? PROMPTS_BY_TYPE[documentHint] || SYSTEM_PROMPT_EXTRACTION
        : SYSTEM_PROMPT_EXTRACTION;

    try {
        const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json',
                'HTTP-Referer': 'https://intelink.app',
                'X-Title': 'Intelink Document Extraction'
            },
            body: JSON.stringify({
                model: model.model_id,
                messages: [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: userPrompt }
                ],
                max_tokens: model.max_tokens,
                temperature: 0.1 // Low temperature for consistent extraction
            })
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`OpenRouter API error: ${response.status} - ${errorText}`);
        }

        const data = await response.json();
        const content = data.choices?.[0]?.message?.content || '';
        
        // Parse JSON from response
        let parsed: Record<string, unknown>;
        try {
            // Try to extract JSON from markdown code blocks if present
            const jsonMatch = content.match(/```(?:json)?\s*([\s\S]*?)```/);
            const jsonStr = jsonMatch ? jsonMatch[1] : content;
            parsed = JSON.parse(jsonStr.trim());
        } catch {
            // If JSON parsing fails, return raw response
            return {
                success: false,
                document_type: documentHint || 'livre',
                model_used: model.name,
                processing_time_ms: Date.now() - start,
                raw_text: text.substring(0, 500),
                summary: 'Erro ao processar resposta do modelo',
                entities: [],
                relationships: [],
                timeline: [],
                insights: [],
                warnings: ['Resposta do modelo nÃ£o Ã© JSON vÃ¡lido'],
                raw_llm_response: content,
                error: 'JSON parsing failed'
            };
        }

        return {
            success: true,
            document_type: (parsed.document_type as DocumentType) || documentHint || 'livre',
            model_used: model.name,
            processing_time_ms: Date.now() - start,
            raw_text: text.substring(0, 500),
            summary: (parsed.summary as string) || '',
            entities: (parsed.entities as ExtractedEntity[]) || [],
            relationships: (parsed.relationships as ExtractedRelationship[]) || [],
            timeline: (parsed.timeline as TimelineEvent[]) || [],
            insights: (parsed.insights as string[]) || [],
            warnings: (parsed.warnings as string[]) || [],
            raw_llm_response: content
        };

    } catch (error) {
        return {
            success: false,
            document_type: documentHint || 'livre',
            model_used: model.name,
            processing_time_ms: Date.now() - start,
            summary: '',
            entities: [],
            relationships: [],
            timeline: [],
            insights: [],
            warnings: [],
            error: error instanceof Error ? error.message : 'Unknown error'
        };
    }
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// FULL PIPELINE
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

export async function processDocument(
    input: string | { filePath: string },
    model: ModelConfig,
    documentHint?: DocumentType
): Promise<ExtractionResult> {
    let text: string;
    
    if (typeof input === 'string') {
        // Free mode - direct text input
        text = input;
    } else {
        // File mode
        try {
            const extracted = await extractTextFromFile(input.filePath);
            text = extracted.text;
        } catch (error) {
            return {
                success: false,
                document_type: documentHint || 'livre',
                model_used: model.name,
                processing_time_ms: 0,
                summary: '',
                entities: [],
                relationships: [],
                timeline: [],
                insights: [],
                warnings: [],
                error: error instanceof Error ? error.message : 'File extraction failed'
            };
        }
    }

    return extractWithLLM(text, model, documentHint);
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// MODEL COMPARISON
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

export interface ModelComparisonResult {
    model: string;
    result: ExtractionResult;
}

export async function compareModels(
    input: string | { filePath: string },
    models: ModelConfig[],
    documentHint?: DocumentType
): Promise<ModelComparisonResult[]> {
    const results: ModelComparisonResult[] = [];
    
    for (const model of models) {
        console.log(`\nğŸ”„ Testing with ${model.name}...`);
        const result = await processDocument(input, model, documentHint);
        results.push({ model: model.name, result });
        
        // Small delay between API calls
        await new Promise(resolve => setTimeout(resolve, 1000));
    }
    
    return results;
}
