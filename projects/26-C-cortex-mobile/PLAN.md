# Cortex Mobile: O "Ladr√£o de Contexto" √âtico

> **Objetivo:** Capturar TUDO o que passa na tela do usu√°rio (ChatGPT, WhatsApp, Emails) para criar um "Segundo C√©rebro" que conecta os pontos.

## üì± A Tecnologia: Android Accessibility Service
Para "ler a tela do usu√°rio" sem root, existe apenas uma porta: **Acessibilidade**.
√â a mesma API que leitores de tela para cegos usam. Ela nos d√° acesso √† √°rvore de visualiza√ß√£o (View Tree) de qualquer app aberto.

### O que √© poss√≠vel extrair?
1.  **Textos:** Mensagens do WhatsApp, respostas do ChatGPT, corpo de emails.
2.  **Input:** O que o usu√°rio est√° digitando (via `TYPE_VIEW_TEXT_CHANGED`).
3.  **Navega√ß√£o:** Saber qual app est√° aberto e em qual tela.

### ‚ö†Ô∏è Permiss√µes Necess√°rias (Grande Barreira)
*   **Permiss√£o Especial:** `BIND_ACCESSIBILITY_SERVICE`.
*   **UX:** O usu√°rio precisa ir em *Configura√ß√µes > Acessibilidade > Cortex > Ativar*. O Android exibe um aviso assustador ("Este app pode ler tudo, incluindo senhas").
*   **Google Play:** Apps com isso s√£o **banidos** se n√£o provarem que ajudam pessoas com defici√™ncia OU se n√£o forem apps corporativos (MDM). Para uso pessoal (Sideload/APK), √© tranquilo.

---

## üèóÔ∏è Arquitetura do MVP

### 1. O "Olho" (Service Layer)
Um `Service` Android rodando em background.
*   **Event Filter:** Escuta apenas `com.whatsapp`, `com.openai.chatgpt`, `com.google.android.gm` (Gmail).
*   **Throttling:** Captura texto apenas quando a tela estabiliza (para n√£o fritar a bateria).

### 2. O "C√©rebro Local" (On-Device AI)
N√£o podemos enviar tudo para a nuvem (privacidade + custo).
*   **Vector DB Local:** Usar **ObjectBox** ou **SQLite-VSS** no celular.
*   **Embeddings:** Rodar um modelo pequeno (ex: `all-MiniLM-L6-v2`) via **ONNX Runtime** no pr√≥prio Android.

### 3. O Fluxo de Dados
1.  **User** abre o ChatGPT e discute "Projeto X".
2.  **Cortex** l√™ a tela: "Contexto: Projeto X, Ideias: A, B, C".
3.  **Cortex** vetoriza e salva localmente com timestamp.
4.  **User** abre o WhatsApp e fala com "S√≥cio" sobre "Projeto X".
5.  **Cortex** detecta a semelhan√ßa sem√¢ntica.
6.  **Notifica√ß√£o Cortex:** "Ei, voc√™ falou sobre isso no ChatGPT h√° 10 mins. Quer ver o resumo?"

---

## üöÄ Plano de Implementa√ß√£o (Roadmap)

### Fase 1: O "Logger" (MVP Inicial)
*   App Android nativo (Kotlin) ou Flutter.
*   Servi√ßo de Acessibilidade configurado.
*   Loga todo texto encontrado em um arquivo `.txt` local seguro.
*   **Entreg√°vel:** Um APK que, quando ativado, gera um "di√°rio" do que voc√™ viu.

### Fase 2: O "Conector"
*   Implementar Database Local.
*   Agrupar logs por "Sess√£o" (ex: conversa do zap das 14:00 √†s 14:10).
*   Envio (opcional) para o `Intelink` (seu PC) via WiFi para processamento pesado.

### Fase 3: A "Intelig√™ncia"
*   RAG Local no celular.
*   Bot√£o flutuante (Overlay) que brilha quando encontra conex√µes.

## üõ°Ô∏è Riscos & Mitiga√ß√£o
1.  **Privacidade:** Dados sens√≠veis (senhas, bancos).
    *   *Solu√ß√£o:* Blacklist de apps (Nubank, Inter) e detec√ß√£o de campos `password`.
2.  **Bateria:** Processar texto consome CPU.
    *   *Solu√ß√£o:* Processamento em "batches" quando a tela apaga.

---

**Veredito:** √â 100% poss√≠vel tecnicamente. A barreira √© a **fric√ß√£o de instala√ß√£o** (o usu√°rio tem que confiar MUITO em voc√™ para dar acesso de Acessibilidade). Como ferramenta *pessoal* ou *enterprise*, √© genial. Como produto de massa na Play Store, √© quase imposs√≠vel aprovar.
